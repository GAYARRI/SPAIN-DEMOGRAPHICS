{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\gayar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GB Regressor on training set over CO(GT): 0.91\n",
      "Accuracy of GB Regressor on test set over CO(GT): 0.87\n",
      "Accuracy of GB Regressor on training set over PT08.S1(CO): 0.91\n",
      "Accuracy of GB Regressor on test set over PT08.S1(CO): 0.89\n",
      "Accuracy of GB Regressor on training set over NMHC(GT): 0.98\n",
      "Accuracy of GB Regressor on test set over NMHC(GT): 0.91\n",
      "Accuracy of GB Regressor on training set over C6H6(GT): 0.99\n",
      "Accuracy of GB Regressor on test set over C6H6(GT): 0.99\n",
      "Accuracy of GB Regressor on training set over PT08.S2(NMHC) : 0.85\n",
      "Accuracy of GB Regressor on test set over PT08.S2(NMHC): 0.82\n",
      "Accuracy of GB Regressor on training set over NOx(GT): 0.84\n",
      "Accuracy of GB Regressor on test set over NOx(GT): 0.79\n",
      "Accuracy of GB Regressor on training set over PT08.S3(NOx) : 0.88\n",
      "Accuracy of GB Regressor on test set over PT08.S3(NOx): 0.85\n",
      "Accuracy of GB Regressor on training set over NO2(GT) : 0.92\n",
      "Accuracy of GB Regressor on test set over NO2(GT): 0.89\n",
      "Accuracy of GB Regressor on training set over PT08.S4(NO2): 0.92\n",
      "Accuracy of GB Regressor on test set over PT08.S4(NO2): 0.91\n",
      "Accuracy of GB Regressor on training set over PT08.S5(O3): 0.82\n",
      "Accuracy of GB Regressor on test set over PT08.S5(O3): 0.77\n",
      "R-squared train score KNN over CO(GT) : 0.860\n",
      "R-squared test score KNN over CO(GT): 0.783\n",
      "R-squared train score KNN over PT08.S1(CO):0.889\n",
      "R-squared test score KNN over PT08.S1(CO):0.803\n",
      "R-squared train score KNN over NMHC(GT):0.896\n",
      "R-squared test score KNN over NMHC(GT):0.790\n",
      "R-squared train score KNN over C6H6(GT) :0.984\n",
      "R-squared test score KNN over C6H6(GT):0.980\n",
      "R-squared train score KNN over PT08.S2(NMHC) : 0.81\n",
      "R-squared test score KNN over PT08.S2(NMHC): 0.67\n",
      "R-squared train score KNNover NOx(GT): 0.82\n",
      "R-squared test score KNN NOx(GT): 0.67\n",
      "R-squared train score KNN over PT08.S3(NOx) : 0.86\n",
      "R-squared test score KNN over PT08.S3(NOx): 0.75\n",
      "R-squared train score KNN over NO2(GT) : 0.81\n",
      "R-squared test score KNN over NO2(GT): 0.68\n",
      "R-squared train score KNN over PT08.S4(NO2): 0.90\n",
      "R-squared test score KNN over PT08.S4(NO2): 0.82\n",
      "R-squared train score KNNover PT08.S5(O3): 0.83\n",
      "R-squared train score KNNover PT08.S5(O3): 0.69\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###### El conjunto de datos contiene 10 indicadores de presencia de determinadas partículas que #########\n",
    "###### se entiende son utilizadas como aproximación de la calidad del aire analizado.Así mismo  #########\n",
    "###### cinco variables de entorno que como hipótesis de trabajo se consideran influyen de       #########\n",
    "###### alguna manera en la presencia/ausencia de dichos indicadores                             #########\n",
    "\n",
    "########################  importamos los paquetes necesarios ############################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "##################   leyendo la data #####################################################################\n",
    "\n",
    "climate = pd.read_table('AirQualityUCI.csv',\";\")\n",
    "climate2=pd.DataFrame(climate)\n",
    "climate2 = climate2.replace({\"-200.0\":\"\"})\n",
    "\n",
    "###########################################################################################################\n",
    "################## generamos un vector por cada parámetro de calidad del aire a estimar  ##################\n",
    "\n",
    "\n",
    "y1=climate2.iloc[0:9357,2]\n",
    "z2=climate2.iloc[0:9357,3]\n",
    "z3=climate2.iloc[0:9357,4]\n",
    "y4=climate2.iloc[0:9357,5]\n",
    "y5=climate2.iloc[0:9357,6]\n",
    "y6=climate2.iloc[0:9357,7]\n",
    "y7=climate2.iloc[0:9357,8]\n",
    "y8=climate2.iloc[0:9357,9]\n",
    "y9=climate2.iloc[0:9357,10]\n",
    "y10=climate2.iloc[0:9357,11]\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "############# construimos la matriz de características explicativas hour, month, T, RH AH  ##################\n",
    "\n",
    "date=climate2.iloc[0:9357,0]\n",
    "date2=climate2.iloc[0:9357,1]\n",
    "\n",
    "hour=[]\n",
    "month=[]\n",
    "for w in date:\n",
    "    sep=w.split(\"/\")\n",
    "    dos=int(sep[1])\n",
    "    month.append(dos)\n",
    "\n",
    "for k in date2:\n",
    "    sep2=k.split(\".\")\n",
    "    dos2=int(sep2[0])\n",
    "    hour.append(dos2) \n",
    "   \n",
    "    \n",
    "X=pd.DataFrame(hour,columns=['hour'])\n",
    "X2=pd.DataFrame(month,columns=['month'])\n",
    "\n",
    "Total=pd.merge(X.reset_index(),X2,left_index=True,right_index=True)\n",
    "\n",
    "T=[]\n",
    "RH=[]\n",
    "AH=[]\n",
    "y1=[]\n",
    "y4=[]\n",
    "\n",
    "###################### los elementos que estan en formato str los convertimos a float ####################### \n",
    "\n",
    "for k in range(9357):\n",
    "\n",
    "    T.append(float(climate2.iloc[k,12].replace(',','.')))\n",
    "    RH.append(float(climate2.iloc[k,13].replace(',','.')))\n",
    "    AH.append(float(climate2.iloc[k,14].replace(',','.')))\n",
    "    y1.append(float(climate2.iloc[k,2].replace(',','.')))\n",
    "    y4.append(float(climate2.iloc[k,5].replace(',','.')))\n",
    "    \n",
    "\n",
    "############################### montamos la matriz de caracteristicas ########################################\n",
    "\n",
    "X=pd.DataFrame(hour,columns=['hour'])\n",
    "X2=pd.DataFrame(month,columns=['month'])\n",
    "\n",
    "Total=pd.merge(X.reset_index(),X2,left_index=True,right_index=True)\n",
    "\n",
    "T=pd.DataFrame(T,columns=['T'])    \n",
    "RH=pd.DataFrame(RH,columns=['RH'])\n",
    "AH=pd.DataFrame(AH,columns=['AH'])\n",
    "Total=pd.merge(Total,T,left_index=True,right_index=True)\n",
    "Total=pd.merge(Total,RH,left_index=True,right_index=True)\n",
    "Total=pd.merge(Total,AH,left_index=True,right_index=True)\n",
    "\n",
    "\n",
    "#######################     montamos las variables dependientes      ###########################################\n",
    "\n",
    "\n",
    "y1=pd.DataFrame(y1,columns=['CO(GT)'])\n",
    "y2=pd.DataFrame(z2,columns=['PT08.S1(CO)'])\n",
    "y3=pd.DataFrame(z3,columns=['NMHC(GT)'])\n",
    "y4=pd.DataFrame(y4,columns=['C6H6(GT)'])\n",
    "y5=pd.DataFrame(y5,columns=['PT08.S2(NMHC)'])\n",
    "y6=pd.DataFrame(y6,columns=['NOx(GT)'])\n",
    "y7=pd.DataFrame(y7,columns=['PT08.S3(NOx)'])\n",
    "y8=pd.DataFrame(y8,columns=['NO2(GT)'])\n",
    "y9=pd.DataFrame(y9,columns=['PT08.S4(NO2)'])\n",
    "y10=pd.DataFrame(y10,columns=['PT08.S5(O3)'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################## bloque optimizable iterando a traves de K=1 to 10 #######################################\n",
    "\n",
    "Total1_train, Total1_test, y1_train, y1_test = train_test_split(Total, y1, random_state = 0)\n",
    "\n",
    "Total2_train, Total2_test, y2_train, y2_test = train_test_split(Total, y2, random_state = 0)\n",
    "\n",
    "Total3_train, Total3_test, y3_train, y3_test = train_test_split(Total, y3, random_state = 0)\n",
    "\n",
    "Total4_train, Total4_test, y4_train, y4_test = train_test_split(Total, y4, random_state = 0)\n",
    "\n",
    "Total5_train, Total5_test, y5_train, y5_test = train_test_split(Total, y5, random_state = 0)\n",
    "\n",
    "Total6_train, Total6_test, y6_train, y6_test = train_test_split(Total, y6, random_state = 0)\n",
    "\n",
    "Total7_train, Total7_test, y7_train, y7_test = train_test_split(Total, y7, random_state = 0)\n",
    "\n",
    "Total8_train, Total8_test, y8_train, y8_test = train_test_split(Total, y8, random_state = 0)\n",
    "\n",
    "Total9_train, Total9_test, y9_train, y9_test = train_test_split(Total, y9, random_state = 0)\n",
    "\n",
    "Total10_train, Total10_test, y10_train, y10_test = train_test_split(Total, y10, random_state = 0)\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#################  METODOS PROBADOS Y DESCARTADOS ( NO SE ADAPTAN BIEN A ESTE CONJUNTO DE DATOS)  ###############\n",
    "\n",
    "\n",
    "#linreg = LinearRegression().fit(X_train, y1_train)\n",
    "\n",
    "#print('R-squared train score LINREG: {:.3f}'\n",
    "#     .format(linreg.score(X_train, y1_train)))\n",
    "#print('R-squared train score LINREG: {:.3f}'\n",
    "#     .format(linreg.score(X_test, y1_test)))\n",
    "\n",
    "\n",
    "#linridge = Ridge(alpha=5.0).fit(X_train, y1_train)\n",
    "\n",
    "#print('R-squared score Ridge1 (training): {:.3f}'\n",
    "#     .format(linridge.score(X_train, y1_train)))\n",
    "#print('R-squared score Ridge1 (test): {:.3f}'\n",
    "#     .format(linridge.score(X_test, y1_test)))\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#linridge = Ridge(alpha=20.0).fit(X_train_scaled, y1_train)\n",
    "\n",
    "#print('R-squared score Ridge2 (training): {:.3f}'\n",
    "#     .format(linridge.score(X_train_scaled, y1_train)))\n",
    "#print('R-squared score Ridge 2(test): {:.3f}'\n",
    "#     .format(linridge.score(X_test_scaled, y1_test)))\n",
    "\n",
    "#poly = PolynomialFeatures(degree=6)\n",
    "#X_poly = poly.fit_transform(X)\n",
    "\n",
    "#X_poly_train, X_poly_test, y1_train, y1_test = train_test_split(X_poly, y1,random_state = 0)\n",
    "#linreg = LinearRegression().fit(X_poly_train, y1_train)\n",
    "\n",
    "#print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "#     .format(linreg.score(X_poly_train, y1_train)))\n",
    "#print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
    "#     .format(linreg.score(X_poly_test, y1_test)))\n",
    "\n",
    "#linreg = Ridge().fit(X_poly_train, y1_train)\n",
    "\n",
    "#print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'\n",
    "#     .format(linreg.score(X_poly_train, y1_train)))\n",
    "#print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'\n",
    "#     .format(linreg.score(X_poly_test, y1_test)))\n",
    "\n",
    "#clf = RandomForestRegressor(n_estimators=500,max_features=1,max_depth=1,random_state = 0)\n",
    "#clf.fit(X_train, y1_train)\n",
    "\n",
    "#print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "#     .format(clf.score(X_train, y1_train)))\n",
    "#print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "#     .format(clf.score(X_test, y1_test)))\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "############################ METODOS VALIDADOS Y ACEPTADOS ( SE ADAPTAN BIEN AL CONJUNTO DE DATOS )  ##############\n",
    "\n",
    "###############   GRADIENT BOOSTING PARA REGRESION PARAMETRIZADO TRATANDO DE EVITAR OVERFITTING  ##################  \n",
    "\n",
    "clf1 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf2 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf3 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf4 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf5 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf6 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf7 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf8 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf9 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "clf10 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,random_state = 0)\n",
    "\n",
    "clf1.fit(Total1_train, y1_train)\n",
    "clf2.fit(Total2_train, y2_train)\n",
    "clf3.fit(Total3_train, y3_train)\n",
    "clf4.fit(Total4_train, y4_train)\n",
    "clf5.fit(Total5_train, y5_train)\n",
    "clf6.fit(Total6_train, y6_train)\n",
    "clf7.fit(Total7_train, y7_train)\n",
    "clf8.fit(Total8_train, y8_train)\n",
    "clf9.fit(Total9_train, y9_train)\n",
    "clf10.fit(Total10_train, y10_train)\n",
    "\n",
    "\n",
    "print('Accuracy of GB Regressor on training set over CO(GT): {:.2f}'\n",
    "     .format(clf1.score(Total1_train, y1_train)))\n",
    "print('Accuracy of GB Regressor on test set over CO(GT): {:.2f}'\n",
    "     .format(clf1.score(Total1_test, y1_test)))\n",
    "print('Accuracy of GB Regressor on training set over PT08.S1(CO): {:.2f}'\n",
    "     .format(clf2.score(Total2_train, y2_train)))\n",
    "print('Accuracy of GB Regressor on test set over PT08.S1(CO): {:.2f}'\n",
    "     .format(clf2.score(Total2_test, y2_test)))\n",
    "print('Accuracy of GB Regressor on training set over NMHC(GT): {:.2f}'\n",
    "     .format(clf3.score(Total3_train, y3_train)))\n",
    "print('Accuracy of GB Regressor on test set over NMHC(GT): {:.2f}'\n",
    "     .format(clf3.score(Total3_test, y3_test)))\n",
    "print('Accuracy of GB Regressor on training set over C6H6(GT): {:.2f}'\n",
    "     .format(clf4.score(Total4_train, y4_train)))\n",
    "print('Accuracy of GB Regressor on test set over C6H6(GT): {:.2f}'\n",
    "     .format(clf4.score(Total4_test, y4_test)))\n",
    "print('Accuracy of GB Regressor on training set over PT08.S2(NMHC) : {:.2f}'\n",
    "     .format(clf5.score(Total5_train, y5_train)))\n",
    "print('Accuracy of GB Regressor on test set over PT08.S2(NMHC): {:.2f}'\n",
    "     .format(clf5.score(Total5_test, y5_test)))\n",
    "print('Accuracy of GB Regressor on training set over NOx(GT): {:.2f}'\n",
    "     .format(clf6.score(Total6_train, y6_train)))\n",
    "print('Accuracy of GB Regressor on test set over NOx(GT): {:.2f}'\n",
    "     .format(clf6.score(Total6_test, y6_test)))\n",
    "print('Accuracy of GB Regressor on training set over PT08.S3(NOx) : {:.2f}'\n",
    "     .format(clf7.score(Total7_train, y7_train)))\n",
    "print('Accuracy of GB Regressor on test set over PT08.S3(NOx): {:.2f}'\n",
    "     .format(clf7.score(Total7_test, y7_test)))\n",
    "print('Accuracy of GB Regressor on training set over NO2(GT) : {:.2f}'\n",
    "     .format(clf8.score(Total8_train, y8_train)))\n",
    "print('Accuracy of GB Regressor on test set over NO2(GT): {:.2f}'\n",
    "     .format(clf8.score(Total8_test, y8_test)))\n",
    "print('Accuracy of GB Regressor on training set over PT08.S4(NO2): {:.2f}'\n",
    "     .format(clf9.score(Total9_train, y9_train)))\n",
    "print('Accuracy of GB Regressor on test set over PT08.S4(NO2): {:.2f}'\n",
    "     .format(clf9.score(Total9_test, y9_test)))\n",
    "print('Accuracy of GB Regressor on training set over PT08.S5(O3): {:.2f}'\n",
    "     .format(clf10.score(Total10_train, y10_train)))\n",
    "print('Accuracy of GB Regressor on test set over PT08.S5(O3): {:.2f}'\n",
    "     .format(clf10.score(Total10_test, y10_test)))\n",
    "\n",
    "##############################        KNN REGRESSOR         ####################################################\n",
    "\n",
    "\n",
    "knnreg1 = KNeighborsRegressor(n_neighbors = 5).fit(Total1_train, y1_train)\n",
    "knnreg2 = KNeighborsRegressor(n_neighbors = 5).fit(Total2_train, y2_train)\n",
    "knnreg3 = KNeighborsRegressor(n_neighbors = 5).fit(Total3_train, y3_train)\n",
    "knnreg4 = KNeighborsRegressor(n_neighbors = 5).fit(Total4_train, y4_train)\n",
    "knnreg5 = KNeighborsRegressor(n_neighbors = 5).fit(Total5_train, y5_train)\n",
    "knnreg6 = KNeighborsRegressor(n_neighbors = 5).fit(Total6_train, y6_train)\n",
    "knnreg7 = KNeighborsRegressor(n_neighbors = 5).fit(Total7_train, y7_train)\n",
    "knnreg8 = KNeighborsRegressor(n_neighbors = 5).fit(Total8_train, y8_train)\n",
    "knnreg9 = KNeighborsRegressor(n_neighbors = 5).fit(Total9_train, y9_train)\n",
    "knnreg10 = KNeighborsRegressor(n_neighbors = 5).fit(Total10_train, y10_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('R-squared train score KNN over CO(GT) : {:.3f}'\n",
    "     .format(knnreg1.score(Total1_train, y1_train)))\n",
    "print('R-squared test score KNN over CO(GT): {:.3f}'\n",
    "     .format(knnreg1.score(Total1_test, y1_test)))\n",
    "print('R-squared train score KNN over PT08.S1(CO):{:.3f}'\n",
    "     .format(knnreg2.score(Total2_train, y2_train)))\n",
    "print('R-squared test score KNN over PT08.S1(CO):{:.3f}'\n",
    "     .format(knnreg2.score(Total2_test, y2_test)))\n",
    "print('R-squared train score KNN over NMHC(GT):{:.3f}'\n",
    "     .format(knnreg3.score(Total3_train, y3_train)))\n",
    "print('R-squared test score KNN over NMHC(GT):{:.3f}'\n",
    "     .format(knnreg3.score(Total3_test, y3_test)))\n",
    "print('R-squared train score KNN over C6H6(GT) :{:.3f}'\n",
    "     .format(knnreg4.score(Total4_train, y4_train)))\n",
    "print('R-squared test score KNN over C6H6(GT):{:.3f}'\n",
    "     .format(knnreg4.score(Total4_test, y4_test)))\n",
    "print('R-squared train score KNN over PT08.S2(NMHC) : {:.2f}'\n",
    "     .format(knnreg5.score(Total5_train, y5_train)))\n",
    "print('R-squared test score KNN over PT08.S2(NMHC): {:.2f}'\n",
    "     .format(knnreg5.score(Total5_test, y5_test)))\n",
    "print('R-squared train score KNNover NOx(GT): {:.2f}'\n",
    "     .format(knnreg6.score(Total6_train, y6_train)))\n",
    "print('R-squared test score KNN NOx(GT): {:.2f}'\n",
    "     .format(knnreg6.score(Total6_test, y6_test)))\n",
    "print('R-squared train score KNN over PT08.S3(NOx) : {:.2f}'\n",
    "     .format(knnreg7.score(Total7_train, y7_train)))\n",
    "print('R-squared test score KNN over PT08.S3(NOx): {:.2f}'\n",
    "     .format(knnreg7.score(Total7_test, y7_test)))\n",
    "print('R-squared train score KNN over NO2(GT) : {:.2f}'\n",
    "     .format(knnreg8.score(Total8_train, y8_train)))\n",
    "print('R-squared test score KNN over NO2(GT): {:.2f}'\n",
    "     .format(knnreg8.score(Total8_test, y8_test)))\n",
    "print('R-squared train score KNN over PT08.S4(NO2): {:.2f}'\n",
    "     .format(knnreg9.score(Total9_train, y9_train)))\n",
    "print('R-squared test score KNN over PT08.S4(NO2): {:.2f}'\n",
    "     .format(knnreg9.score(Total9_test, y9_test)))\n",
    "print('R-squared train score KNNover PT08.S5(O3): {:.2f}'\n",
    "     .format(knnreg10.score(Total10_train, y10_train)))\n",
    "print('R-squared train score KNNover PT08.S5(O3): {:.2f}'\n",
    "     .format(knnreg10.score(Total10_test, y10_test)))\n",
    "\n",
    "\n",
    "#### lA ALTERNATIVA EN TERMINOS DE RRNN DE COSTO COMPUTACIONAL BAJO NO MEJORA LOS CLASIFICADORES OBTENIDOS #####\n",
    "\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "#X10_train, X10_test, y10_train, y10_test = train_test_split(Total, y10, random_state = 0)\n",
    "#X10_train_scaled = scaler.fit_transform(X10_train)\n",
    "#X10_test_scaled = scaler.transform(X10_test)\n",
    "\n",
    "#clf = MLPRegressor(hidden_layer_sizes = [100,100,100], alpha = 5,activation='relu',learning_rate='adaptive',\n",
    "#                   random_state = 0, solver='lbfgs').fit(X10_train_scaled, y10_train)\n",
    "\n",
    "#print('Accuracy of NN classifier on training set: {:.2f}'\n",
    "#     .format(clf.score(X10_train_scaled, y10_train)))\n",
    "#print('Accuracy of NN classifier on test set: {:.2f}'\n",
    "#     .format(clf.score(X10_test_scaled, y10_test)))        \n",
    "    \n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  La conclusion es que ambos modelos obitienen resultados que avalan la hipótesis de que los 10 indicadores ######\n",
    "###  de calidad del aire dependen en gran medida de las variables de entorno consideradas ( día del mes , mes, ######\n",
    "###  temperatura, humedad realativa, y humedad absoluta ) .                                                    ######\n",
    "###  El más eficiente de los dos modelos considerados Gradient Boosting Regressor , consique los siguientes \n",
    "###  scores en elconjunto de test 0.87,0.89,0.91,0.99,0.82,0.79,0.85,0.89,0.91,0.77 .                          ###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
